{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtnRZzOd3IOnFJ8j1FWTfG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c1f9c119c8a4ebcb92767066b64b7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_282639c8cd6a4bbeb51ab53a43b6099a",
              "IPY_MODEL_e7efb18dbddc47eb9bd5c757ca29d6a3",
              "IPY_MODEL_d4a1009f6d1440c981c2e449750ab4a4"
            ],
            "layout": "IPY_MODEL_1dc6762857ea4a47a62a9957d16c2bdb"
          }
        },
        "282639c8cd6a4bbeb51ab53a43b6099a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d15562d7a4d40d2894b8a30cb9afd55",
            "placeholder": "​",
            "style": "IPY_MODEL_8c9ea021752b4ce6afec55fe17e6233a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e7efb18dbddc47eb9bd5c757ca29d6a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc093593a4254c1b81489f814b430a2f",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce64bc3fe6344fedb2e6cd496c1086e2",
            "value": 7
          }
        },
        "d4a1009f6d1440c981c2e449750ab4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b49f016d6614d2dbd1d998930920103",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd53f5c72354c999fcd31b4d007051b",
            "value": " 7/7 [00:05&lt;00:00,  1.28it/s]"
          }
        },
        "1dc6762857ea4a47a62a9957d16c2bdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d15562d7a4d40d2894b8a30cb9afd55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9ea021752b4ce6afec55fe17e6233a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc093593a4254c1b81489f814b430a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce64bc3fe6344fedb2e6cd496c1086e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b49f016d6614d2dbd1d998930920103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd53f5c72354c999fcd31b4d007051b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malongfei1993/longTextSummary_chatglm3-6b-32k/blob/main/chatglm3_peft_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_rqTfGxd93-",
        "outputId": "f608c797-3696-43a8-e319-d99542132047"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHf6zWuyePd8",
        "outputId": "37f8b554-04d7-4e16-f3d6-cb032e1fcab7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.34.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.14.1)\n",
            "Collecting huggingface-hub>=0.17.0 (from peft)\n",
            "  Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.16.1 requires huggingface-hub>=0.19.4, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae1babLPfOal",
        "outputId": "04976d5e-0ed6-4a87-d729-24153dbfb834"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.23.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.34.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Collecting huggingface-hub>=0.19.4 (from datasets)\n",
            "  Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall transformers"
      ],
      "metadata": {
        "id": "mF2H0y_8fRhN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里需要指定下transformers版本"
      ],
      "metadata": {
        "id": "t0iVI5wm0BRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers==4.34.0"
      ],
      "metadata": {
        "id": "f6zd8tkufViX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# 模型ID或本地路径\n",
        "model_name_or_path = 'THUDM/chatglm3-6b'"
      ],
      "metadata": {
        "id": "e535ybCTezdP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_compute_dtype_map = {\n",
        "    'fp32': torch.float32,\n",
        "    'fp16': torch.float16,\n",
        "    'bf16': torch.bfloat16\n",
        "}\n",
        "\n",
        "# QLoRA 量化配置\n",
        "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                              bnb_4bit_quant_type='nf4',\n",
        "                              bnb_4bit_use_double_quant=True,\n",
        "                              bnb_4bit_compute_dtype=_compute_dtype_map['bf16'])\n",
        "# 加载量化后模型\n",
        "base_model = AutoModel.from_pretrained(model_name_or_path,\n",
        "                                  quantization_config=q_config,\n",
        "                                  device_map='auto',\n",
        "                                  trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "0c1f9c119c8a4ebcb92767066b64b7f9",
            "282639c8cd6a4bbeb51ab53a43b6099a",
            "e7efb18dbddc47eb9bd5c757ca29d6a3",
            "d4a1009f6d1440c981c2e449750ab4a4",
            "1dc6762857ea4a47a62a9957d16c2bdb",
            "5d15562d7a4d40d2894b8a30cb9afd55",
            "8c9ea021752b4ce6afec55fe17e6233a",
            "bc093593a4254c1b81489f814b430a2f",
            "ce64bc3fe6344fedb2e6cd496c1086e2",
            "7b49f016d6614d2dbd1d998930920103",
            "0bd53f5c72354c999fcd31b4d007051b"
          ]
        },
        "id": "03taURi_e05a",
        "outputId": "d026175e-8998-49d2-984f-2377b35db205"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c1f9c119c8a4ebcb92767066b64b7f9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.requires_grad_(False)\n",
        "base_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEeKyaMhe46-",
        "outputId": "0bc7f231-d318-446a-feaa-6fb92018193b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGLMForConditionalGeneration(\n",
              "  (transformer): ChatGLMModel(\n",
              "    (embedding): Embedding(\n",
              "      (word_embeddings): Embedding(65024, 4096)\n",
              "    )\n",
              "    (rotary_pos_emb): RotaryEmbedding()\n",
              "    (encoder): GLMTransformer(\n",
              "      (layers): ModuleList(\n",
              "        (0-27): 28 x GLMBlock(\n",
              "          (input_layernorm): RMSNorm()\n",
              "          (self_attention): SelfAttention(\n",
              "            (query_key_value): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
              "            (core_attention): CoreAttention(\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          )\n",
              "          (post_attention_layernorm): RMSNorm()\n",
              "          (mlp): MLP(\n",
              "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
              "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layernorm): RMSNorm()\n",
              "    )\n",
              "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "r1SZvaTte_ku"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def compare_chatglm_results(query):\n",
        "#     base_response, base_history = base_model.chat(tokenizer, query,temperature=0.1,history=[])\n",
        "\n",
        "#     # inputs = tokenizer(query, return_tensors=\"pt\").to(0)\n",
        "#     # ft_out = model.generate(**inputs, max_new_tokens=512,temperature=0.1)\n",
        "#     # ft_response = tokenizer.decode(ft_out[0], skip_special_tokens=True)\n",
        "#     print(base_response)\n",
        "#     # print(f\"问题：{query}\\n\\n原始输出：\\n{base_response}\\n\\n\\nChatGLM3-6B微调后：\\n{ft_response}\")\n",
        "#     return base_response"
      ],
      "metadata": {
        "id": "LF24riGXfzrz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = '''这是数据：{\n",
        "\"ID\": NaN,\n",
        "\"General characteristics\": \"Unit scope\",\n",
        "\"Information\": NaN,\n",
        "\"Value\": \"Cover lens+Panel + backlight + T-CON + Optical bonding + Touch function\",\n",
        "\"Response\": NaN\n",
        "},\n",
        "{\n",
        "\"ID\": \"1.1\",\n",
        "\"General characteristics\": \"Display size\",\n",
        "\"Information\": \"Disassociated Center Stack Display w/ Oversized Lens design\",\n",
        "\"Value\": \"12.9\" (Supplier to suggest better size)\",\n",
        "\"Response\": \"2023/10/25: 12.8\" FHD\"\n",
        "},\n",
        "{\n",
        "\"ID\": 1.2,\n",
        "\"General characteristics\": \"Orientation\",\n",
        "\"Information\": \"Portrait / Landscape\\u2026\",\n",
        "\"Value\": \"Landscape\",\n",
        "\"Response\": NaN\n",
        "},----------\n",
        "请回复如下格式：\n",
        "[{\n",
        "\"参数\":\"\",\n",
        "\"需求规格\":\"\",\n",
        "\"\"供应商反馈\"\"：\"\"\n",
        "}]\n",
        "你的任务：\n",
        "提取对角线尺寸的参数规格需求信息和供应商反馈信息。\n",
        "下面是你的回复(使用英文)：'''"
      ],
      "metadata": {
        "id": "OIIi9uZ4xfjj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response, history = base_model.chat(tokenizer,test_text,temperature=0.1,history=[])\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "9TGEaWLwmUA5",
        "outputId": "81b093ae-2152-4e7c-81c1-4f9408b4dfa1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n\"参数\": \"Display size\",\\n\"需求规格\": \"12.9\" (Supplier to suggest better size)\",\\n\"供应商反馈\": \"2023/10/25: 12.8\" FHD\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**问题出现在下面这段加载peft这里，只要执行完这段代码，原来模型的输出就变成与微调后的输出一样**"
      ],
      "metadata": {
        "id": "4H1pjzUyzlrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "epochs = 5\n",
        "peft_model_path = f\"drive/MyDrive/fineTuningModel/models/THUDM/chatglm3-6b-epoch{epochs}\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_path)\n",
        "model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
        "# model = AutoModel.from_pretrained(peft_model_path,device_map=\"auto\",trust_remote_code=True)"
      ],
      "metadata": {
        "id": "CANGGZ98xcAr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS9ZK10d5mnM",
        "outputId": "94654b98-bc4e-4fd2-ac72-fb0ea8d84416"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): ChatGLMForConditionalGeneration(\n",
              "      (transformer): ChatGLMModel(\n",
              "        (embedding): Embedding(\n",
              "          (word_embeddings): Embedding(65024, 4096)\n",
              "        )\n",
              "        (rotary_pos_emb): RotaryEmbedding()\n",
              "        (encoder): GLMTransformer(\n",
              "          (layers): ModuleList(\n",
              "            (0-27): 28 x GLMBlock(\n",
              "              (input_layernorm): RMSNorm()\n",
              "              (self_attention): SelfAttention(\n",
              "                (query_key_value): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.05, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=16, out_features=4608, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (core_attention): CoreAttention(\n",
              "                  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "              )\n",
              "              (post_attention_layernorm): RMSNorm()\n",
              "              (mlp): MLP(\n",
              "                (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
              "                (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (final_layernorm): RMSNorm()\n",
              "        )\n",
              "        (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uxunhIMQbp0",
        "outputId": "e5ea0b89-3f86-437e-b506-c431b828a223"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGLMForConditionalGeneration(\n",
              "  (transformer): ChatGLMModel(\n",
              "    (embedding): Embedding(\n",
              "      (word_embeddings): Embedding(65024, 4096)\n",
              "    )\n",
              "    (rotary_pos_emb): RotaryEmbedding()\n",
              "    (encoder): GLMTransformer(\n",
              "      (layers): ModuleList(\n",
              "        (0-27): 28 x GLMBlock(\n",
              "          (input_layernorm): RMSNorm()\n",
              "          (self_attention): SelfAttention(\n",
              "            (query_key_value): lora.Linear4bit(\n",
              "              (base_layer): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
              "              (lora_dropout): ModuleDict(\n",
              "                (default): Dropout(p=0.05, inplace=False)\n",
              "              )\n",
              "              (lora_A): ModuleDict(\n",
              "                (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "              )\n",
              "              (lora_B): ModuleDict(\n",
              "                (default): Linear(in_features=16, out_features=4608, bias=False)\n",
              "              )\n",
              "              (lora_embedding_A): ParameterDict()\n",
              "              (lora_embedding_B): ParameterDict()\n",
              "            )\n",
              "            (core_attention): CoreAttention(\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          )\n",
              "          (post_attention_layernorm): RMSNorm()\n",
              "          (mlp): MLP(\n",
              "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
              "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layernorm): RMSNorm()\n",
              "    )\n",
              "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**这是微调后的输出**，可以执行下base_model的那行，输出变得与微调后的一样了"
      ],
      "metadata": {
        "id": "eTlG_m5ozuWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response, history = model.chat(tokenizer,test_text,temperature=0.1,history=[])\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "XKtGQsN4pPqf",
        "outputId": "ab0d3b15-ddf9-4845-c8c6-56ac5ee489c2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n\"参数\": \"Display size\",\\n\"需求规格\": \"12.9\" (Supplier to suggest better size)\",\\n\"供应商反馈\": \"2023/10/25: 12.8\" FHD\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_response = compare_chatglm_results(query='''\n",
        "# 这是数据：{\n",
        "# \"ID\": NaN,\n",
        "# \"General characteristics\": \"Unit scope\",\n",
        "# \"Information\": NaN,\n",
        "# \"Value\": \"Cover lens+Panel + backlight + T-CON + Optical bonding + Touch function\",\n",
        "# \"Response\": NaN\n",
        "# },\n",
        "# {\n",
        "# \"ID\": \"1.1\",\n",
        "# \"General characteristics\": \"Display size\",\n",
        "# \"Information\": \"Disassociated Center Stack Display w/ Oversized Lens design\",\n",
        "# \"Value\": \"12.9\" (Supplier to suggest better size)\",\n",
        "# \"Response\": \"2023/10/25: 12.8\" FHD\"\n",
        "# },\n",
        "# {\n",
        "# \"ID\": 1.2,\n",
        "# \"General characteristics\": \"Orientation\",\n",
        "# \"Information\": \"Portrait / Landscape\\u2026\",\n",
        "# \"Value\": \"Landscape\",\n",
        "# \"Response\": NaN\n",
        "# },----------\n",
        "# 请回复如下格式：\n",
        "# [{\n",
        "# \"参数\":\"\",\n",
        "# \"需求规格\":\"\",\n",
        "# \"\"供应商反馈\"\"：\"\"\n",
        "# }]\n",
        "# 你的任务：\n",
        "# 提取对角线尺寸的参数规格需求信息和供应商反馈信息。\n",
        "# 下面是你的回复(使用英文)：\n",
        "\n",
        "\n",
        "# ''')"
      ],
      "metadata": {
        "id": "VGpWHHxYf16i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}